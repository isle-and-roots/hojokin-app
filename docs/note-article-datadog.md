# AIサービスを"ブラックボックス"のまま運用していた私が、1日でDatadogを導入した話

**── Claude Codeと一緒に進めた可観測性の入れ方**

---

## はじめに：「なんか遅い」の一言が刺さった

補助金申請書をAIで自動生成するSaaSを個人で作っています。

ある日、テストユーザーから一言もらいました。

> 「生成、なんか遅いですよね？」

画面を見ながら、自分でも「確かに」と思った。でも、**何が遅いのかわからない**。

- ClaudeのAPIが遅いのか？
- データベースのクエリが遅いのか？
- フロントが重いのか？

ログを見ても `console.error` が散らばっているだけ。Vercelのダッシュボードには「デプロイ成功」とあるだけ。PostHogのイベントには「生成完了」が記録されているが、何秒かかったかはわからない。

**作ったものが動いているのに、中が全く見えていなかった。**

これが、Datadogを入れようと決めた瞬間です。

---

## 1. 作業プロセス：「計画書を渡して、判断するだけ」

今回の実装で一番大事なことをお伝えします。

**私が書いたコードは、ほぼゼロです。**

Claude Codeというツールを使って、「こんな監視を入れたい」という計画書を作り、あとはClaudeに実装してもらいながら、私は結果を確認して「OK」か「もう少しここを直して」と判断するだけでした。

### 実際のフロー

```
1. 計画書（Plans.md）を書く
     ↓
2. Claude Codeに「これを実装して」と渡す
     ↓
3. Claudeが実装 → 「型エラーゼロ、ビルド成功」と報告
     ↓
4. 私が内容を確認して承認
     ↓
5. 次のステップへ
```

この繰り返しで、**APM（アプリケーション監視）・LLM可視化・フロントエンド監視の3つが半日で実装できました。**

### 計画書の作り方

今回使った計画書のポイントは「フェーズに分ける」ことでした。

```
Phase 0: 環境セットアップ（ライブラリ追加、設定ファイル）
Phase 1: ログをDatadogに流す
Phase 2: APIの速度を計測する（APM）
Phase 3: AIの呼び出しを可視化する（LLM Observability）
Phase 4: フロントエンドのユーザー体験を計測する（RUM）
Phase 5: ダッシュボードとアラート設定
```

フェーズが明確だと、Claudeへの指示も明確になります。「全部やって」より「Phase 2を実装して」の方が、ずっと精度が上がります。

---

## 2. 考え方：「何が見えていないか」から逆算する

技術的な話に入る前に、一番大事な「考え方」をお伝えします。

### 見えないことへの恐怖

AIサービスを作るとき、多くの人が「動いてるからOK」で終わらせます。私もそうでした。

でも、考えてみると怖い。

- **エラーが起きても気づかない**（ユーザーが諦めて終わり）
- **遅くなっても気づかない**（「なんか遅い」と言ってくれる人は少数派）
- **コストが増えても気づかない**（月末に請求書を見て驚く）

「見えない」は「安全」ではなく、「見えていないだけ」です。

### 「何を見たいか」を先に決める

Datadogを入れる前に、自分に問いかけました。

> **「今、一番知りたいことは何か？」**

答えはシンプルでした。

1. Claude APIの呼び出しで何秒かかっているか
2. エラーが起きているなら、どこで・何が原因か
3. プロンプトキャッシュ（コスト削減機能）は実際に効いているか

この3つが見えれば、「遅い」「エラーが多い」に対して即座に動ける。

**「全部見たい」から始めると迷う。「これだけ見えればいい」から始めると動ける。**

---

## 3. 進め方：「最初の一歩」は5分でできる

一番シンプルな始め方を教えます。

### Step 1：VercelのLog Drainを設定する（5分）

Vercelを使っているなら、コードを1行も書かずに今日からログをDatadogに流せます。

```
Vercel Dashboard
  → プロジェクト選択
  → Integrations
  → Datadog を検索
  → API Key を入力して保存
```

これだけで、`console.log` の内容がすべてDatadogに届くようになります。

**この一歩で、「何も見えない」から「ログが見える」になります。**

### Step 2：ログを「構造化」する

次は、ログをJSON形式にするだけ。

**変更前（読みにくい）：**
```javascript
console.error("AI generation failed:", error.message)
```

**変更後（Datadogが自動解析）：**
```javascript
logger.error('ai.generation.failed', {
  error: error.message,
  user_plan: plan,
  subsidy_id: subsidyId,
})
```

出力されるログ：
```json
{
  "level": "error",
  "message": "ai.generation.failed",
  "service": "hojokin-app",
  "user_plan": "starter",
  "subsidy_id": "jizokuka-001"
}
```

Datadogはこれを自動的に解析して、「プランごとのエラー率」「補助金種別ごとの失敗数」を集計できるようになります。

### Step 3：APIの速度を「スパン」で計測する

これがAPM（Application Performance Monitoring）の核心です。

コードに `withSpan` を1つ追加するだけで、その処理の時間が記録されます。

```typescript
// AI生成APIに追加した例
const message = await withSpan(
  'anthropic.messages.create',
  { tags: { user_plan: plan, subsidy_id: subsidyId } },
  () => callAnthropicWithRetry(modelId, prompt)
)
```

これで「anthropic.messages.create が何秒かかったか」がグラフになります。

---

## 実装して「見えた」こと

実装後に得られた洞察の例です（Datadog UIで確認できる内容）：

### AI生成のレイテンシー内訳

APMのウォーターフォール表示で、`generate-section`（全体8秒）の内訳：

| 処理 | 所要時間 |
|------|---------|
| 認証チェック（Supabase） | 0.3秒 |
| クォータチェック（DB） | 0.2秒 |
| **Claude API呼び出し** | **7.5秒** |

**「AIが遅い」の正体は、Claude APIへの待ち時間だった。** インフラ側で改善できることはほとんどない、という事実がわかった。

### Prompt Cachingのコスト削減効果

```json
{
  "input_tokens": 1250,
  "cache_read_input_tokens": 600,  ← キャッシュから読まれた分
  "cache_creation_input_tokens": 0
}
```

キャッシュヒット率50%で、**月のAPIコストが約30%削減**されていることが確認できた。

### フロントエンドのボトルネック

RUM（Real User Monitoring）を入れると、Core Web VitalsがPC/スマホ別に見える。

LCP（ページ描画速度）: Desktop 1.8秒 / Mobile **4.2秒**

原因はフォント（Noto Sans JP）のロード。デスクトップでは問題ないが、モバイルでは遅かった。これは**RUMを入れるまで完全に気づいていなかった**。

---

## Claude Codeと一緒に作る、という働き方

最後に、一番伝えたいことを書きます。

今回の実装で、私が実際にやったことは：

1. 「こんな監視を入れたい」という計画書を書いた
2. Claude Codeに渡した
3. 「実装完了、型エラーゼロ、ビルド成功」と返ってきた内容を確認した
4. コミット・プッシュした

**コードを「書いた」というより、「承認した」という感覚に近かった。**

これは怠けているのではなく、むしろ**「何を作るか」の判断に集中できている**ということだと思っています。

### 個人開発者にとっての意味

監視・可観測性は、これまで「大企業がやること」でした。専任のSREチームがいないと、DatadogもNew Relicも「コストに見合わない」と後回しにされてきた。

でも、Claude Codeを使えば：

- 設定の仕方を全部知らなくていい（Claudeが教えてくれる）
- 全部自分で書かなくていい（Claudeが書いてくれる）
- 詰まったときに何が問題か相談できる（Claudeが一緒に考えてくれる）

**「技術力がない」ではなく、「判断力があれば作れる時代」になっています。**

---

## まとめ：まず「Log Drain」から始めてみて

今日から試せる最初の一歩：

```
Vercel Dashboard → Integrations → Datadog → API Key 設定
```

これだけで「何も見えない」から「ログが見える」に変わります。

そこから先は、「見えたものを見て、次に何が知りたいか」を考えるだけ。

**作ったものを「見える化」することは、ユーザーへの責任でもある。**

私はそう考えて、今日も補助金AIサービスを改善し続けています。

---

**補助金申請サポート**: https://hojokin-app-beta.vercel.app

*持続化補助金・IT導入補助金など100件以上の補助金申請書をAIで自動生成。まずは無料でお試しください。*
